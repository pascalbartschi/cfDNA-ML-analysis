{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf93e49",
   "metadata": {},
   "source": [
    "# Implement K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1eb62d",
   "metadata": {},
   "source": [
    "### import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b081b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa725544",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1748f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"Results/Machine_Learning/sample_map_ML.csv\")\n",
    "features  = pd.read_csv(\"Results/Machine_Learning/fragment_features_CNA_ML.csv\")\n",
    "# convert to long\n",
    "features = pd.pivot(data = features, index = \"sample\", columns = \"length\", values = \"count\")\n",
    "# convert into binary column\n",
    "cancer_list = [\"A\", \"B\", \"C\", \"Lung\", \"Breast\"]\n",
    "\n",
    "def binary(df):\n",
    "    df[\"cancer\"] = np.where(df[\"diagnosis\"].isin(cancer_list), 1, 0)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "# apply function and reshape df\n",
    "labels = binary(labels)\n",
    "labels.drop(columns = [\"diagnosis\"], inplace = True)\n",
    "labels.set_index(\"sample\", inplace = True)\n",
    "\n",
    "# convert into numpy vectors\n",
    "features = features.to_numpy(copy=True) \n",
    "labels = labels.to_numpy(copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1b21a",
   "metadata": {},
   "source": [
    "### Train test split & kFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dc58f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CV_analysis(split_, n_params, t_knn, t_logReg, t_ranFor):\n",
    "    F1_matrix_knn = {\"n_neighbors\": []}\n",
    "    F1_matrix_logReg = {\"C_value\": []}\n",
    "    F1_matrix_ranFor = {\"n_estimators\": []}\n",
    "\n",
    "\n",
    "    for index, (i_train, i_valid) in enumerate(split_):\n",
    "        # splitting into train and validation set\n",
    "        X_train, X_valid = X[i_train], X[i_valid]\n",
    "        y_train, y_valid = y[i_train], y[i_valid]\n",
    "        \n",
    "        transformer = StandardScaler().fit(X_train) # compute mean, std on train\n",
    "        X_valid = transformer.transform(X_valid)  # use same transformer for both, mimics that we do not know train data\n",
    "        X_train = transformer.transform(X_train)\n",
    "\n",
    "        # loop through each classifier, fit and predict the validation set\n",
    "\n",
    "        for n_neighbors in np.linspace(t_knn[0], t_knn[1], n_params, dtype = \"int\"):\n",
    "\n",
    "            # construct new Fi columns if i doesnt exist     \n",
    "            if \"F\" + str(index+1) not in F1_matrix_knn.keys():\n",
    "                F1_matrix_knn[\"F\" + str(index+1)] = []\n",
    "\n",
    "            # fit and predict with classifier\n",
    "            knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_predict = knn.predict(X_valid)\n",
    "\n",
    "            # insert F1 value in matrix\n",
    "            F1_matrix_knn[\"F\" + str(index+1)].append(f1_score(y_valid, y_predict, average = \"macro\"))\n",
    "\n",
    "            # for index labeling with paramters\n",
    "            if n_neighbors not in F1_matrix_knn[\"n_neighbors\"]:\n",
    "                F1_matrix_knn[\"n_neighbors\"].append(n_neighbors)\n",
    "                \n",
    "           # print(\"KNN: {} accuracy train: {} vs. valid {}\".format(n_neighbors,\n",
    "           #                                                      accuracy_score(y_train, knn.predict(X_train)),\n",
    "           #                                                      accuracy_score(y_valid, knn.predict(X_valid))))\n",
    "            \n",
    "            \n",
    "\n",
    "        # same as above        \n",
    "        for C_value in np.linspace(t_logReg[0], t_logReg[1], n_params):\n",
    "\n",
    "\n",
    "            if \"F\" + str(index+1) not in F1_matrix_logReg.keys():\n",
    "\n",
    "                F1_matrix_logReg[\"F\" + str(index+1)] = []\n",
    "\n",
    "            logReg = LogisticRegression(penalty = \"l1\", solver = \"liblinear\", max_iter = 1000, C = C_value)\n",
    "            logReg.fit(X_train, y_train)\n",
    "            y_predict = logReg.predict(X_valid)\n",
    "\n",
    "            F1_matrix_logReg[\"F\" + str(index+1)].append(f1_score(y_valid, y_predict, average = \"macro\"))\n",
    "\n",
    "            if C_value not in F1_matrix_logReg[\"C_value\"]:\n",
    "                F1_matrix_logReg[\"C_value\"].append(C_value)\n",
    "                \n",
    "            # print(\"LogReg: {} accuracy train: {} vs. valid {}\".format(C_value,\n",
    "            #                                                     accuracy_score(y_train, logReg.predict(X_train)),\n",
    "            #                                                     accuracy_score(y_valid, logReg.predict(X_valid))))\n",
    "\n",
    "        # same as above        \n",
    "        for n_estimators in np.linspace(t_ranFor[0], t_ranFor[1], n_params, dtype = \"int\"):\n",
    "\n",
    "\n",
    "            if \"F\" + str(index+1) not in F1_matrix_ranFor.keys():\n",
    "\n",
    "                F1_matrix_ranFor[\"F\" + str(index+1)] = []\n",
    "\n",
    "            ranFor = RandomForestClassifier(n_estimators = n_estimators, max_depth = 6) \n",
    "            ranFor.fit(X_train, y_train)\n",
    "            y_predict = ranFor.predict(X_valid)\n",
    "\n",
    "            F1_matrix_ranFor[\"F\" + str(index+1)].append(f1_score(y_valid, y_predict, average = \"macro\"))\n",
    "\n",
    "            if n_estimators not in F1_matrix_ranFor[\"n_estimators\"]:\n",
    "                F1_matrix_ranFor[\"n_estimators\"].append(n_estimators)\n",
    "                \n",
    "            # print(\"ranFor: {} accuracy train: {} vs. valid {}\".format(n_estimators,\n",
    "            #                                                      accuracy_score(y_train, ranFor.predict(X_train)),\n",
    "            #                                                      accuracy_score(y_valid, ranFor.predict(X_valid))))\n",
    "\n",
    "\n",
    "    F1_knn = pd.DataFrame(F1_matrix_knn)\n",
    "    F1_knn.set_index(\"n_neighbors\", inplace = True)\n",
    "    F1_knn = F1_knn.round(decimals = 4)\n",
    "\n",
    "    F1_logReg = pd.DataFrame(F1_matrix_logReg)\n",
    "    F1_logReg.set_index(\"C_value\", inplace = True)\n",
    "    F1_logReg = F1_logReg.round(decimals = 4)\n",
    "\n",
    "    F1_ranFor = pd.DataFrame(F1_matrix_ranFor)\n",
    "    F1_ranFor.set_index(\"n_estimators\", inplace = True)\n",
    "    F1_ranFor = F1_ranFor.round(decimals = 4)\n",
    "    \n",
    "    return F1_knn, F1_logReg, F1_ranFor\n",
    "            \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6dc4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = features, labels.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33, shuffle = True)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "split_ = kf.split(X_train)\n",
    "\n",
    "\n",
    "n_params = 3\n",
    "t_knn = (4, 6)\n",
    "t_logReg = (0.01, 1000)\n",
    "t_ranFor = (45, 55)\n",
    "# call func\n",
    "F1_knn, F1_logReg, F1_ranFor = CV_analysis(split_, n_params, t_knn, t_logReg, t_ranFor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d5fe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 F1      F2      F3      F4      F5\n",
      "n_neighbors                                        \n",
      "4            0.7493  0.6375  0.8504  0.6976  0.7761\n",
      "5            0.7735  0.6842  0.8504  0.7839  0.8130\n",
      "6            0.7493  0.6976  0.8311  0.7227  0.7948\n",
      "              F1      F2      F3      F4      F5\n",
      "C_value                                         \n",
      "0.010     0.4167  0.3937  0.4122  0.4122  0.3871\n",
      "500.005   0.9345  0.8839  0.9690  0.8727  0.9123\n",
      "1000.000  0.9045  0.8839  0.9690  0.8587  0.9123\n",
      "                  F1      F2      F3      F4      F5\n",
      "n_estimators                                        \n",
      "45            0.7107  0.7017  0.8409  0.7175  0.8672\n",
      "50            0.7493  0.6935  0.8548  0.7839  0.8510\n",
      "55            0.7358  0.6842  0.8587  0.7580  0.8377\n"
     ]
    }
   ],
   "source": [
    "print(F1_knn)\n",
    "print(F1_logReg)\n",
    "print(F1_ranFor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ffbf4d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1444702770.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [68]\u001b[1;36m\u001b[0m\n\u001b[1;33m    F1_ranFor = F1_ranFor.assign(mean = F1_ranFor.iloc[:, :5]mean(axis=1)) # assign add a column to df\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# add some stats\n",
    "\n",
    "F1_knn = F1_knn.assign(mean = F1_knn.iloc[:, :5].mean(axis=1)) # assign add a column to df\n",
    "F1_knn = F1_knn.assign(sd = F1_knn.iloc[:, :5].std(axis = 1))\n",
    "\n",
    "F1_logReg = F1_logReg.assign(mean = F1_logReg.iloc[:, :5].mean(axis=1)) # assign add a column to df\n",
    "F1_logReg = F1_logReg.assign(sd = F1_logReg.iloc[:, :5].std(axis = 1))\n",
    "\n",
    "F1_ranFor = F1_ranFor.assign(mean = F1_ranFor.iloc[:, :5].mean(axis=1)) # assign add a column to df\n",
    "F1_ranFor = F1_ranFor.assign(sd = F1_ranFor.iloc[:, :5].std(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ba37db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\"classifier\": [\"KNN\", \"Logistic Regression\", \"Random Forest\"],\n",
    "                        \"mean_F1\": [F1_knn.iloc[1, 5], F1_logReg.iloc[1, 5], F1_ranFor.iloc[1, 5]],\n",
    "                       \"std_F1\": [F1_knn.iloc[1, 6], F1_logReg.iloc[1, 6], F1_ranFor.iloc[1, 6]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39482d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.barplot(summary, x = summary.classifier, y = summary.mean_F1, errorbar = summary.std_F1)\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.bar(data = summary, x = \"classifier\", height = \"mean_F1\", yerr = \"std_F1\", color = [\"#1b8ce0\", \"#e06666\", \"#6eb250\"],\n",
    "        capsize=10)\n",
    "plt.title(\"Classifier F1 performance\")\n",
    "plt.xlabel(\"Classifiers\")\n",
    "plt.ylabel(\"Mean F1-score\") # put definition of macro F1 score, sensitivity and specificity -> doesnt favour one level over the other\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "523f764d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>std_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.651720</td>\n",
       "      <td>0.054323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.034383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RanFor</td>\n",
       "      <td>0.678059</td>\n",
       "      <td>0.065566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier   mean_F1    std_F1\n",
       "0        KNN  0.651720  0.054323\n",
       "1     LogReg  0.811570  0.034383\n",
       "2     RanFor  0.678059  0.065566"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fee7d6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_neighbors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.657655</td>\n",
       "      <td>0.190590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>0.7688</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.682579</td>\n",
       "      <td>0.190197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6980</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.8455</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.661332</td>\n",
       "      <td>0.187228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F1      F2      F3      F4      F5      mean        sd\n",
       "n_neighbors                                                            \n",
       "4            0.7358  0.6225  0.8399  0.7462  0.7568  0.657655  0.190590\n",
       "5            0.7100  0.7298  0.8504  0.7688  0.7818  0.682579  0.190197\n",
       "6            0.6980  0.6856  0.8455  0.7358  0.7568  0.661332  0.187228"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
